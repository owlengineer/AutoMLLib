# AutoMLLib

Данная библиотека предоставляет интерфейс для обучения моделей для задачи бинарной классификации.

# Features

1. Получение лучшей модели для поданных данных (на основе подсчета метрики каждую эпоху)
2. Рандомизация параметров отдельных моделей -- библиотека обучает каждую модель несколько раз, рандомизируя её параметры при каждом пайплайне. Так увеличивается шанс на получение более точной модели.

### ToDo 

1. Интерфейс получения predictions от модели (абстрактный метод predict в классе BaseModelWrapper (под реализацию в потомках) и метод predict в BinaryClassifier)
2. Для увеличения точности -- обучение всего перечня доступных моделей (models package)
   1. Чтобы отсеивать модели с неподходящими параметрами -- создать checker входных параметров (через вот это https://python-jsonschema.readthedocs.io/en/stable/)
   2. Чтобы аналитик понял что было проверено -- по завершении обучения выводить summary в виде:
      1. Успех/неуспех(неподходящие параметры) - модель - результат метрики 
3. Для увеличения точности в нейросетевых решениях -- прописать package с блоками слоев (Inpu, Dense, DropOut и т.п), чтобы структуру нейросети тоже рандомизировать перемешивая блоки между собой

## install (Linux)

Установка в venv (Poetry):
```commandline
(venv) $ poetry add git+ssh://git@github.com:owlengineer/AutoMLLib.git
```

## Usage

Пример обучения модели DumbDenseNet:
```python
from automllib.models.DumbDenseNet import DumbDenseNet
from keras.metrics import TruePositives

#
# ... prepare x_train, y_train, x_test, y_test data

# параметры, у каждой модели своя JSON-SCHEMA параметров 
params = {
        'metric_fn': TruePositives(),  # функцию можно реализовать самостроятельно или выбрать готовую
        'epochs': 10,
        'batch_size': 32,
        'validation_split': 0.2,
        'input_shape': (1000,)
    }
model = DumbDenseNet(params=params)
best_model, metric_result = model.get_best_model(x_train, y_train,  
                                                 x_test, y_test)

```
Таким образом best_model -- Python-объект модели, а metric_result -- расчет метрики на тестовых данных.

## Ход мыслей (как делал)

<details>
  <summary>Expand!</summary>
<br>

### Исходная постановка

Библиотека должна решать задачу бинарной классификации для заданной выборки. Финальная модель должна выбираться на основе выбранной метрики. Решение о том, какие библиотеки использовать в коде и как будет выглядеть пайплайн обучения остаётся за тобой.

Есть два момента которые стоит учесть:

1. Стоит помнить, что твой код это именно библиотека, то есть она может использоваться другими людьми. Поэтому не забудь про readme и про примеры использования.
2. Не нужно писать библиотеку, которая будет имеет несомненную практическую ценность. Нам важно посмотреть, как у тебя получается продумывать архитектуру библиотеки и писать код на Python для автоматизации data science задач.

### Декомпозиция

1. Библиотека должна иметь понятную инструкцию к установке и описание API (примеры). 
2. Библиотека должна поддерживать множество моделей и эти модели должны иметь единый интерефейс взаимодействия с пользователем
3. Базовое API -- обучение модели, на вход пользователь подает: (1, required) датасет, заранее подготовленный; (2, optional) гиперпараметры модели и метрику, на выход -- объект  модели и расчет метрики.
4. Модель на выходе должна быть лучшей комбинацией весов (а не последней, например)
5. Покрытие тестами, которое как минимум проверяет что модели в принципе собираются и обучаются. 

### Реализация

1. Библиотека обернута в poetry-пакет с помощью pyproject.toml, README содержит примеры того, как работать с библиотекой, и как установить её в свой venv
2. Общий интерфейс сделан через общий для всех моделей класс BaseModelWrapper. В нем есть абстрактные методы которые классам-потомкам (непосредственно моделям) надо переопределить. 
3. Базовая функция для пользователя -- get_best_model(data), она запускает процесс обучения, возвращает объект модели и расчет метрики. Пользовательские конфиги модели (кол-во эпох, размер батча, метрика и тп) подаются в конструктор как словарь params -- в этом универсальность, но для каждой модели поля могут быть разные. Пример -- если использовать https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html, там параметры будут другие, нежели в реализации через нейронную сеть. 
4. Данный пункт реализовывается в методе тренировки модели самим разработчиком, поскольку реализация метода тренировки может быть разная (например если цикл обучения спрятан во внешней функции, а callback-ов как в keras-e нет)
5. Реализация подразумевает, что для каждой модели будет проводиться 2 теста -- на успешную сборку и успешное обучение. Для модели-примера на Dense слоях это сделано. Использовался pytest.
</details>
